{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd47993c-a6aa-457a-ac17-6fa1c0862aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import charset_normalizer\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c537fa7-b68e-4c71-879a-fcef6df8f9f1",
   "metadata": {},
   "source": [
    "\n",
    "## What are encodings?\n",
    "\n",
    "Character encodings are specific sets of rules for mapping from raw binary byte strings (that look like this: 0110100001101001) to characters that make up human-readable text (like \"hi\"). There are many different encodings, and if you tried to read in text with a different encoding than the one it was originally written in, you ended up with scrambled text called \"mojibake\" (said like mo-gee-bah-kay). Here's an example of mojibake:\n",
    "\n",
    "æ–‡å—åŒ–ã??\n",
    "\n",
    "You might also end up with a \"unknown\" characters. There are what gets printed when there's no mapping between a particular byte and a character in the encoding you're using to read your byte string in and they look like this:\n",
    "\n",
    "����������\n",
    "\n",
    "Character encoding mismatches are less common today than they used to be, but it's definitely still a problem. There are lots of different character encodings, but the main one you need to know is UTF-8.\n",
    "\n",
    "- UTF-8 is the standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. It's when things aren't in UTF-8 that you run into trouble.\n",
    "\n",
    "It was pretty hard to deal with encodings in Python 2, but thankfully in Python 3 it's a lot simpler. (Kaggle Notebooks only use Python 3.) There are two main data types you'll encounter when working with text in Python 3. One is is the string, which is what text is by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f43bdd-18ea-4385-86ea-a24e353044d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = 'This is the euro symbol: €'\n",
    "type(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4d068c-3f5e-4298-8aed-3987426ae4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after = before.encode('utf-8',errors = 'replace')\n",
    "type(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7de6dd-2922-487e-b080-e4902add1b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is the euro symbol: \\xe2\\x82\\xac'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f704f831-70ec-4828-a62b-fde045cdde1a",
   "metadata": {},
   "source": [
    "If you look at a bytes object, you'll see that it has a b in front of it, and then maybe some text after. That's because bytes are printed out as if they were characters encoded in ASCII. (ASCII is an older character encoding that doesn't really work for writing any language other than English.) Here you can see that our euro symbol has been replaced with some mojibake that looks like \"\\xe2\\x82\\xac\" when it's printed as if it were an ASCII string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a138658-c478-4aef-94dc-5e27a3d9bd98",
   "metadata": {},
   "source": [
    "**When we convert our bytes back to a string with the correct encoding, we can see that our text is all there correctly, which is great! :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691dae24-48d6-4227-8abd-355c0674cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "print(after.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccda7ac-13fe-42eb-b6c5-d2eb79e0fb20",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "However, when we try to use a different encoding to map our bytes into a string, we get an error. This is because the encoding we're trying to use doesn't know what to do with the bytes we're trying to pass it. You need to tell Python the encoding that the byte string is actually supposed to be in.\n",
    "\n",
    "- You can think of different encodings as different ways of recording music. You can record the same music on a CD, cassette tape or 8-track. While the music may sound more-or-less the same, you need to use the right equipment to play the music from each recording format. The correct decoder is like a cassette player or a CD player. If you try to play a cassette in a CD player, it just won't work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fe1dbd-42b4-4ddb-8e54-01df88f44a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# try to decode our bytes with the ascii encoding\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(after.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# try to decode our bytes with the ascii encoding\n",
    "print(after.decode(\"ascii\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a6801-a0a3-4e15-a66a-7bb80ef8a5d8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can also run into trouble if we try to use the wrong encoding to map from a string to bytes. Like I said earlier, strings are UTF-8 by default in Python 3, so if we try to treat them like they were in another encoding we'll create problems.\n",
    "\n",
    "For example, if we try to convert a string to bytes for ASCII using encode(), we can ask for the bytes to be what they would be if the text was in ASCII. Since our text isn't in ASCII, though, there will be some characters it can't handle. We can automatically replace the characters that ASCII can't handle. If we do that, however, any characters not in ASCII will just be replaced with the unknown character. Then, when we convert the bytes back to a string, the character will be replaced with the unknown character. The dangerous part about this is that there's not way to tell which character it should have been. That means we may have just made our data unusable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd4a4127-c5f9-45e3-93a2-9dcf9a982bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: ?\n"
     ]
    }
   ],
   "source": [
    "# start with a string\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# convert it back to utf-8\n",
    "print(after.decode(\"ascii\"))\n",
    "\n",
    "# We've lost the original underlying byte string! It's been \n",
    "# replaced with the underlying byte string for the unknown character :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f230712-86c1-4a0c-9f8d-476ff1157d19",
   "metadata": {},
   "source": [
    "**This is bad and we want to avoid doing it! It's far better to convert all our text to UTF-8 as soon as we can and keep it in that encoding. The best time to convert non UTF-8 input into UTF-8 is when you read in files, which we'll talk about next.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a036c7a-4a9c-4eda-ad01-210d15b560b4",
   "metadata": {},
   "source": [
    "## Reading in files with encoding problems¶\n",
    "\n",
    "Most files you'll encounter will probably be encoded with UTF-8. This is what Python expects by default, so most of the time you won't run into problems. However, sometimes you'll get an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7026ba-975c-4a55-b205-f8534f5d2a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
